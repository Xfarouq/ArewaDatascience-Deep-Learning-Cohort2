{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_pytorch_computer_vision_exercises.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Arewa Data Science Academy\n",
        "## Deep Learning Cohort2.0\n",
        "## Name: Umar Lawan Sani\n",
        "### Email: umarfarouq447@gmail.com\n",
        "### Title: Week 4 Solution\n",
        "### Exercises Solution"
      ],
      "metadata": {
        "id": "Vex99np2wFVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaeYzOTLwWh2",
        "outputId": "474f127e-07a3-4858-afcd-602e8e57f73e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Feb 27 16:53:49 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8             14W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Exercises require PyTorch > 1.10.0\n",
        "print(torch.__version__)\n",
        "\n",
        "# TODO: Setup device agnostic code\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNwZLMbCzJLk",
        "outputId": "df4443db-283d-4ee7-f5ac-b5d05060b900"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What are 3 areas in industry where computer vision is currently being used?"
      ],
      "metadata": {
        "id": "FSFX7tc1w-en"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Healthcare\n",
        "## Transportation\n",
        "## Retail & E-Commerce"
      ],
      "metadata": {
        "id": "V3J1TOsWV57x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Healthcare\n",
        "# Transportation\n",
        "# Retail & E-Commerce"
      ],
      "metadata": {
        "id": "VyWRkvWGbCXj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find."
      ],
      "metadata": {
        "id": "oBK-WI6YxDYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overfitting in machine learning occurs when a model learns not only the underlying patterns in the training data but also the noise and outliers, leading to poor performance on unseen data."
      ],
      "metadata": {
        "id": "uCCSfI97WGVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Overfitting in machine learning occurs when a model learns not only the underlying patterns in the training data but also the noise and outliers, leading to poor performance on unseen data."
      ],
      "metadata": {
        "id": "d1rxD6GObCqh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each.\n",
        "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
      ],
      "metadata": {
        "id": "XeYFEqw8xK26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regularization\n",
        "## Increase Number of Hidden Layers\n",
        "## Cross-Validation"
      ],
      "metadata": {
        "id": "yFUXOiPhWTAK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ocvOdWKcbEKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
      ],
      "metadata": {
        "id": "DKdEEFEqxM-8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TqZaJIRMbFtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
      ],
      "metadata": {
        "id": "lvf-3pODxXYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define transformations (convert images to tensors and normalize)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load the MNIST train and test datasets\n",
        "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
        "\n",
        "# Print dataset sizes\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n"
      ],
      "metadata": {
        "id": "SHjeuN81bHza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7172e42d-1ab2-4c62-aed9-d806246075dc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.58MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 134kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.08MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.70MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Train dataset size: 60000\n",
            "Test dataset size: 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Visualize at least 5 different samples of the MNIST training dataset."
      ],
      "metadata": {
        "id": "qxZW-uAbxe_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Select 5 random samples from the dataset\n",
        "fig, axes = plt.subplots(1, 5, figsize=(10, 2))\n",
        "for i in range(5):\n",
        "    image, label = train_dataset[i]  # Get image and label\n",
        "    image = image.squeeze().numpy()  # Convert to NumPy array and remove extra dimensions\n",
        "\n",
        "    axes[i].imshow(image, cmap=\"gray\")  # Display the image\n",
        "    axes[i].set_title(f\"Label: {label}\")\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QVFsYi1PbItE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "outputId": "74843bac-33ee-4717-a889-24d3d9c5b054"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
      ],
      "metadata": {
        "id": "JAPDzW0wxhi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Set batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create DataLoaders for train and test datasets\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Print the number of batches\n",
        "print(f\"Number of training batches: {len(train_loader)}\")\n",
        "print(f\"Number of testing batches: {len(test_loader)}\")\n"
      ],
      "metadata": {
        "id": "ALA6MPcFbJXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8473225-4907-4881-f971-a757f2812191"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training batches: 1875\n",
            "Number of testing batches: 313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
      ],
      "metadata": {
        "id": "bCCVfXk5xjYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the TinyVGG model (model_2)\n",
        "class TinyVGG(nn.Module):\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)  # Downsampling\n",
        "        )\n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)  # Downsampling\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(hidden_units * 7 * 7, output_shape)  # Output 10 classes for MNIST\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model for MNIST (1 input channel, 10 output classes)\n",
        "model_2 = TinyVGG(input_shape=1, hidden_units=64, output_shape=10)\n",
        "\n",
        "# Print model summary\n",
        "print(model_2)\n"
      ],
      "metadata": {
        "id": "5IKNF22XbKYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d534daa2-75f0-4f94-a0f9-da301f7052d0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TinyVGG(\n",
            "  (conv_block1): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv_block2): Sequential(\n",
            "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=3136, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
      ],
      "metadata": {
        "id": "sf_3zUr7xlhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "# Set device-agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Move model to the selected device\n",
        "model_2 = model_2.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_2.parameters(), lr=0.001)\n",
        "\n",
        "# Training function\n",
        "def train_model(model, dataloader, loss_fn, optimizer, device, epochs=5):\n",
        "    model.train()  # Set to training mode\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Compute loss & accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss/len(dataloader):.4f} - Accuracy: {correct/total:.4f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Training completed in {end_time - start_time:.2f} seconds.\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "jSo6vVWFbNLD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Training on CPU...\")\n",
        "model_2.to(\"cpu\")  # Move model to CPU\n",
        "train_model(model_2, train_loader, loss_fn, optimizer, \"cpu\", epochs=5)\n"
      ],
      "metadata": {
        "id": "cDxET0dBYCzI",
        "outputId": "1cabe591-df1f-44f3-c24f-e8d61d0744b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on CPU...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"Training on GPU...\")\n",
        "    model_2.to(\"cuda\")  # Move model to GPU\n",
        "    train_model(model_2, train_loader, loss_fn, optimizer, \"cuda\", epochs=5)\n",
        "else:\n",
        "    print(\"GPU not available, skipping GPU training.\")\n"
      ],
      "metadata": {
        "id": "UPlUvy-2YByB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
      ],
      "metadata": {
        "id": "w1CsHhPpxp1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Function to make predictions and visualize results\n",
        "def visualize_predictions(model, dataloader, device, num_samples=5):\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    fig, axes = plt.subplots(1, num_samples, figsize=(10, 2))\n",
        "\n",
        "    # Get a batch of images and labels\n",
        "    images, labels = next(iter(dataloader))\n",
        "    images, labels = images[:num_samples].to(device), labels[:num_samples].to(device)\n",
        "\n",
        "    # Make predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        predictions = outputs.argmax(1)  # Get predicted class\n",
        "\n",
        "    # Visualize the images along with predictions\n",
        "    for i in range(num_samples):\n",
        "        image = images[i].cpu().squeeze().numpy()  # Convert tensor to NumPy\n",
        "        axes[i].imshow(image, cmap=\"gray\")\n",
        "        axes[i].set_title(f\"Pred: {predictions[i].item()}\\nLabel: {labels[i].item()}\")\n",
        "        axes[i].axis(\"off\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Move model to the correct device (CPU/GPU)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_2.to(device)\n",
        "\n",
        "# Visualize predictions\n",
        "visualize_predictions(model_2, test_loader, device)\n"
      ],
      "metadata": {
        "id": "_YGgZvSobNxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
      ],
      "metadata": {
        "id": "qQwzqlBWxrpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Function to make predictions and generate a confusion matrix\n",
        "def plot_confusion_matrix(model, dataloader, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Make predictions\n",
        "            outputs = model(images)\n",
        "            preds = outputs.argmax(1)  # Get predicted class\n",
        "\n",
        "            # Store predictions and labels\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=range(10), yticklabels=range(10))\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.title(\"Confusion Matrix for MNIST Predictions\")\n",
        "    plt.show()\n",
        "\n",
        "# Move model to device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_2.to(device)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plot_confusion_matrix(model_2, test_loader, device)\n"
      ],
      "metadata": {
        "id": "vSrXiT_AbQ6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
      ],
      "metadata": {
        "id": "lj6bDhoWxt2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Create a random tensor of shape [1, 3, 64, 64] (batch_size=1, channels=3, height=64, width=64)\n",
        "random_tensor = torch.rand(1, 3, 64, 64)\n",
        "\n",
        "# Function to apply Conv2d with different kernel sizes and print output shape\n",
        "def test_conv2d(kernel_size):\n",
        "    conv_layer = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=kernel_size, stride=1, padding=0)\n",
        "    output = conv_layer(random_tensor)\n",
        "    print(f\"Kernel Size: {kernel_size} -> Output Shape: {output.shape}\")\n",
        "\n",
        "# Test different kernel sizes\n",
        "for k in [1, 3, 5, 7, 9]:\n",
        "    test_conv2d(k)\n"
      ],
      "metadata": {
        "id": "leCTsqtSbR5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset.\n",
        "* Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
        "* After visualing these predictions do you think it's more of a modelling error or a data error?\n",
        "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ],
      "metadata": {
        "id": "VHS20cNTxwSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define transformations (convert images to tensors and normalize)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load FashionMNIST train and test datasets\n",
        "fashion_train_dataset = torchvision.datasets.FashionMNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "fashion_test_dataset = torchvision.datasets.FashionMNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 32\n",
        "fashion_test_loader = torch.utils.data.DataLoader(fashion_test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# FashionMNIST class labels\n",
        "fashion_classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "                   \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n"
      ],
      "metadata": {
        "id": "78a8LjtdbSZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_2.to(device)\n",
        "model_2.eval()  # Set model to evaluation mode\n",
        "\n",
        "# Get predictions on test set\n",
        "incorrect_samples = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in fashion_test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Make predictions\n",
        "        outputs = model_2(images)\n",
        "        preds = outputs.argmax(1)  # Get predicted class\n",
        "\n",
        "        # Store incorrect predictions\n",
        "        for i in range(len(labels)):\n",
        "            if preds[i] != labels[i]:  # If prediction is incorrect\n",
        "                incorrect_samples.append((images[i], preds[i], labels[i]))\n",
        "\n",
        "        # Stop once we collect 5 incorrect samples\n",
        "        if len(incorrect_samples) >= 5:\n",
        "            break\n"
      ],
      "metadata": {
        "id": "rE0pXp7cZCq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot 5 incorrect predictions\n",
        "fig, axes = plt.subplots(1, 5, figsize=(10, 2))\n",
        "\n",
        "for i in range(5):\n",
        "    image, pred_label, true_label = incorrect_samples[i]\n",
        "    image = image.cpu().squeeze().numpy()  # Convert tensor to NumPy\n",
        "\n",
        "    axes[i].imshow(image, cmap=\"gray\")\n",
        "    axes[i].set_title(f\"Pred: {fashion_classes[pred_label.item()]}\\nTrue: {fashion_classes[true_label.item()]}\")\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zJJslz2UZE-Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}